{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes prediction: random forest\n",
    "\n",
    "## Notebook set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds on the decision tree analysis by implementing **Random Forest** - an ensemble method that combines multiple decision trees for better performance. We import the same libraries as before, plus `RandomForestClassifier` and add a waiting mechanism to ensure the decision tree notebook has completed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard library imports\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# PyPI imports - data manipulation and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# PyPI imports - statistical and machine learning libraries\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Internal imports - project-specific modules\n",
    "import configuration as config\n",
    "import functions as funcs\n",
    "\n",
    "# Wait for the decision tree notebook to finish execution\n",
    "while True:\n",
    "    if os.path.exists(config.DECISION_TREE_MODEL):\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading\n",
    "\n",
    "### 1.1. Load data from disk\n",
    "\n",
    "Load the pre-processed data from the decision tree notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of repeating the data preprocessing steps, we load the already cleaned and split dataset from the decision tree notebook. This ensures consistency across all algorithm comparisons and saves computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed dataset that was saved from the decision tree notebook\n",
    "with open(config.DATA_FILE, 'rb') as input_file:\n",
    "    dataset = pickle.load(input_file)\n",
    "\n",
    "# Extract training and testing dataframes from the loaded dictionary\n",
    "training_df = dataset['training']\n",
    "testing_df = dataset['testing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick verification that we've loaded the correct preprocessed dataset with the expected features and format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model training\n",
    "\n",
    "### 2.1. Previous scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin the Random Forest modeling process by first loading previous model results, then training both a basic and optimized Random Forest. This ensemble method should outperform the single decision tree by reducing overfitting through averaging multiple trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cross validation scores from previous models\n",
    "with open(config.CROSS_VAL_SCORES_FILE, 'rb') as input_file:\n",
    "    cross_val_scores = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the cross-validation scores from previous models (logistic regression, decision tree, optimized decision tree) to maintain a comprehensive comparison across all algorithms tested in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Random forest model\n",
    "\n",
    "Score a random forest model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is an ensemble method that builds multiple decision trees and averages their predictions. Key advantages:\n",
    "- **Reduced overfitting**: Multiple trees reduce variance compared to a single tree\n",
    "- **Better generalization**: Averaging helps smooth out individual tree quirks\n",
    "- **Feature randomness**: Each tree uses a random subset of features, improving robustness\n",
    "- **Parallel training**: Trees can be trained independently, making it scalable\n",
    "\n",
    "We start with default hyperparameters using the same preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of features to impute\n",
    "with open(config.IMPUTED_FEATURES_FILE, 'rb') as input_file:\n",
    "    imputed_features = pickle.load(input_file)\n",
    "\n",
    "# Create the imputer\n",
    "knn_imputer = ColumnTransformer([('imputer', KNNImputer(), imputed_features)], remainder='passthrough')\n",
    "\n",
    "# Create a random forest classifier with default hyperparameters\n",
    "tree_model = RandomForestClassifier(\n",
    "    class_weight=config.CLASS_WEIGHT,  # Handle class imbalance\n",
    "    random_state=config.RANDOM_SEED    # Ensure reproducible results\n",
    ")\n",
    "\n",
    "naive_model = Pipeline(\n",
    "    steps=[\n",
    "        ('KNN', knn_imputer),\n",
    "        ('classifier', tree_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the naive random forest model\n",
    "naive_model.fit(training_df.drop('Outcome', axis=1), training_df['Outcome'])\n",
    "\n",
    "# Calculate and display training accuracy\n",
    "accuracy = accuracy_score(naive_model.predict(training_df.drop('Outcome', axis=1)), training_df['Outcome'])*100\n",
    "print(f'Training accuracy of random forest: {accuracy:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation provides an unbiased estimate of Random Forest performance. We expect this ensemble method to show:\n",
    "- **Lower variance**: More consistent performance across different data subsets\n",
    "- **Better average performance**: Typically outperforms single decision trees\n",
    "- **Reduced overfitting**: Less prone to memorizing training data quirks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation on the naive random forest model\n",
    "scores = cross_val_score(\n",
    "    naive_model,\n",
    "    training_df.drop('Outcome', axis=1),\n",
    "    training_df['Outcome'],\n",
    "    cv=config.CROSS_VAL,        # Use stratified shuffle split for cross-validation\n",
    "    n_jobs=-1                   # Use all available CPU cores for parallel processing\n",
    ")\n",
    "\n",
    "# Store results for comparison with previous models and future optimized model\n",
    "cross_val_scores['Model'].extend(['Random forest']*len(scores))\n",
    "cross_val_scores['Score'].extend(scores * 100)\n",
    "\n",
    "# Display cross-validation results with mean and standard deviation\n",
    "print(f'Cross-validation accuracy of random forest: {np.mean(scores)*100:.1f} +/- {np.std(scores)*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter optimization\n",
    "\n",
    "### 3.1. Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest hyperparameter optimization focuses on both individual tree parameters and ensemble-specific settings:\n",
    "\n",
    "**Imputation parameters**: Control how missing values are filled\n",
    "\n",
    "**Ensemble parameters**: \n",
    "- `n_estimators`: Number of trees in the forest (more trees = better performance but slower training)\n",
    "\n",
    "**Individual tree parameters**: Same as decision trees (depth, splits, leaf constraints)\n",
    "\n",
    "Optimization should improve upon the baseline Random Forest performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define hyperparameter search space for random forest optimization\n",
    "hyperparameters = {\n",
    "    'KNN__imputer__n_neighbors': randint(1, 3),\n",
    "    'KNN__imputer__weights': ['uniform', 'distance'],\n",
    "    'KNN__imputer__add_indicator': [True, False],\n",
    "    'classifier__n_estimators': randint(2, 200),\n",
    "    'classifier__criterion':['gini','entropy','log_loss'],\n",
    "    'classifier__max_depth':randint(1, 20),\n",
    "    'classifier__min_samples_split':randint(2, 40),\n",
    "    'classifier__min_samples_leaf':randint(1, 20),\n",
    "    'classifier__min_weight_fraction_leaf':loguniform(10**-5, 0.5),\n",
    "    'classifier__max_features':uniform(loc=0.1, scale=0.9),\n",
    "    'classifier__max_leaf_nodes':randint(2, 100),\n",
    "    'classifier__min_impurity_decrease':loguniform(10**-5, 1.0),\n",
    "    'classifier__ccp_alpha':loguniform(10**-5, 10.0)\n",
    "}\n",
    "\n",
    "# Perform randomized search over hyperparameters\n",
    "search = RandomizedSearchCV(\n",
    "    naive_model,\n",
    "    hyperparameters,\n",
    "    return_train_score=True,                 # Return training scores for analysis\n",
    "    cv=config.CROSS_VAL,\n",
    "    n_jobs=-1,                               # Use all available CPU cores\n",
    "    n_iter=config.RANDOM_SEARCH_ITERATIONS,  # Number of parameter combinations to try\n",
    "    random_state=config.RANDOM_SEED          # Ensure reproducible results\n",
    ")\n",
    "\n",
    "# Fit the search and extract best model and parameters\n",
    "search_results = search.fit(training_df.drop('Outcome', axis=1), training_df['Outcome'])\n",
    "best_model = search_results.best_estimator_\n",
    "winning_hyperparameters = search_results.best_params_\n",
    "\n",
    "# Display the best hyperparameters found\n",
    "print('Best hyperparameters:\\n')\n",
    "\n",
    "for key, value in winning_hyperparameters.items():\n",
    "    print(f' {key}: {value}')\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'Run time ({os.cpu_count()} CPUs):\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Hyperparameter optimization results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the hyperparameter search results to understand how much hyperparameters matter and whether we found good solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs.plot_cross_validation(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Cross-validation of optimized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the optimized Random Forest using the same cross-validation approach to fairly compare with all previous models. This will reveal the performance gain from hyperparameter tuning on the ensemble method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation on the optimized random forest model\n",
    "scores = cross_val_score(\n",
    "    best_model,\n",
    "    training_df.drop('Outcome', axis=1),\n",
    "    training_df['Outcome'],\n",
    "    cv=config.CROSS_VAL,\n",
    "    n_jobs=-1                   # Use all available CPU cores for parallel processing\n",
    ")\n",
    "\n",
    "# Store results for comparison with all other models\n",
    "cross_val_scores['Model'].extend(['Optimized random forest']*len(scores))\n",
    "cross_val_scores['Score'].extend(scores * 100)\n",
    "\n",
    "# Display cross-validation results for the optimized random forest\n",
    "print(f'Optimized random forest cross-validation accuracy: {np.mean(scores)*100:.1f} +/- {np.std(scores)*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "### 4.1. Cross-validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare Random Forest performance against all previous models to understand:\n",
    "- **Ensemble advantage**: How much improvement Random Forest provides over single trees\n",
    "- **Model ranking**: Where Random Forest stands in our algorithm comparison\n",
    "- **Consistency**: Whether Random Forest shows more stable performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot to compare cross-validation performance\n",
    "models = ['Logistic regression', 'Random forest', 'Optimized random forest']\n",
    "plot_scores = pd.DataFrame.from_dict(cross_val_scores)\n",
    "plot_scores = plot_scores[plot_scores['Model'].isin(models)]\n",
    "\n",
    "sns.boxplot(plot_scores, x='Model', y='Score')\n",
    "plt.title('Cross-validation performance comparison')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xticks(rotation=35, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A focused comparison of the most relevant models: logistic regression baseline, basic Random Forest, and optimized Random Forest. This shows the progression from linear model to ensemble method and the benefit of hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Test set performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final evaluation on the held-out test set reveals true model performance on completely unseen data. The confusion matrices will show:\n",
    "- **Ensemble stability**: Whether Random Forest predictions are more reliable\n",
    "- **Class balance**: How well each model handles both diabetic and non-diabetic cases\n",
    "- **Real-world performance**: The ultimate test of model effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain both naive and optimized random forest models on the full training set\n",
    "result = naive_model.fit(training_df.drop('Outcome', axis=1), training_df['Outcome'])\n",
    "result = best_model.fit(training_df.drop('Outcome', axis=1), training_df['Outcome'])\n",
    "\n",
    "# Load the logistic regression model for comparison\n",
    "with open(config.LOGISTIC_REGRESSION_MODEL, 'rb') as input_file:\n",
    "    linear_model = pickle.load(input_file)\n",
    "\n",
    "# Generate confusion matrices for both random forest models on the test set\n",
    "funcs.plot_confusion_matrices(\n",
    "    models = {\n",
    "        'Logistic regression': linear_model,\n",
    "        'Random forest': naive_model,\n",
    "        'Optimized random forest': best_model\n",
    "    },\n",
    "    testing_df=testing_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save\n",
    "\n",
    "### 5.1. Cross-validation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the Random Forest results to build our comprehensive model comparison database for the final project evaluation and to preserve the trained models for potential deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.CROSS_VAL_SCORES_FILE, 'wb') as output_file:\n",
    "    pickle.dump(cross_val_scores, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update our cross-validation scores database with Random Forest results for use in subsequent notebooks (gradient boosting) and final model comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the optimized Random Forest model and its hyperparameters for:\n",
    "- **Deployment**: The model can be loaded and used for predictions\n",
    "- **Reproducibility**: Exact hyperparameters can be recreated\n",
    "- **Comparison**: Other notebooks can load and compare against this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimal hyperparameters for future use or reproduction\n",
    "with open(config.RANDOM_FOREST_HYPERPARAMETERS, 'wb') as output_file:\n",
    "    pickle.dump(winning_hyperparameters, output_file)\n",
    "\n",
    "# Save the trained best random forest model for deployment or further analysis\n",
    "with open(config.RANDOM_FOREST_MODEL, 'wb') as output_file:\n",
    "    pickle.dump(best_model, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
