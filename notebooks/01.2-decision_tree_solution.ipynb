{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes prediction: decision tree\n",
    "\n",
    "## Notebook set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard library imports\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "# PyPI imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Internal imports\n",
    "import configuration as config\n",
    "import functions as funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading\n",
    "\n",
    "### 1.1. Load data from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/4GeeksAcademy/decision-tree-project-tutorial/main/diabetes.csv'\n",
    "data_df = pd.read_csv(url)\n",
    "data_df.drop_duplicates().reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Save a local copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory for raw data\n",
    "Path('../data/raw').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save a local copy of the raw data\n",
    "data_df.to_parquet('../data/raw/medical-insurance-cost.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "### 2.1. Data composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pregnancies','Glucose','BloodPressure','SkinThickness',\n",
    "            'Insulin','BMI','DiabetesPedigreeFunction','Age']\n",
    "\n",
    "fig, axs = plt.subplots(2,4, figsize=(12,6))\n",
    "axs = axs.flatten()\n",
    "\n",
    "fig.suptitle('Feature distributions')\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    axs[i].hist(data_df[feature], color='black', bins=30)\n",
    "    axs[i].set_xlabel(feature)\n",
    "    axs[i].set_ylabel('Patients')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Feature interactions\n",
    "\n",
    "#### 2.2.1. Feature cross-correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pairs = sorted(map(sorted, combinations(set(features), 2)))\n",
    "rows = len(feature_pairs) // 4\n",
    "\n",
    "fig, axs = plt.subplots(rows,4, figsize=(10,rows*2.5), layout='constrained')\n",
    "axs = axs.flatten()\n",
    "\n",
    "fig.suptitle('Feature correlations')\n",
    "\n",
    "for i, feature_pair in enumerate(feature_pairs):\n",
    "    axs[i].scatter(data_df[feature_pair[0]], data_df[feature_pair[1]], color='black', s=0.5)\n",
    "    axs[i].set_xlabel(feature_pair[0])\n",
    "    axs[i].set_ylabel(feature_pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Feature-label interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize=(10,5))\n",
    "axs = axs.flatten()\n",
    "\n",
    "fig.suptitle('Feature distributions by outcome')\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "\n",
    "    sns.boxplot(data_df, x='Outcome', y=feature, ax=axs[i])\n",
    "    axs[i].set_title(feature)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preparation\n",
    "\n",
    "### 3.1. Test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, testing_df = train_test_split(\n",
    "    data_df,\n",
    "    test_size=0.5\n",
    ")\n",
    "\n",
    "print(f'Training set: {len(training_df)} rows')\n",
    "print(f'Testing set: {len(testing_df)} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Imputation of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_fraction = (training_df[features] == 0).astype(int).sum(axis=0) / len(training_df)\n",
    "zero_fraction.sort_values(inplace=True)\n",
    "\n",
    "plt.title('Fraction zeros by feature')\n",
    "plt.bar(zero_fraction.index, zero_fraction, color='black')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Fraction zeros')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_features = ['Insulin','SkinThickness','BloodPressure','BMI','Glucose']\n",
    "knn_imputer = KNNImputer(missing_values=0.0, weights='distance')\n",
    "knn_imputer.fit(training_df[imputed_features])\n",
    "training_df[imputed_features] = knn_imputer.transform(training_df[imputed_features])\n",
    "testing_df[imputed_features] = knn_imputer.transform(testing_df[imputed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pregnancies','Glucose','BloodPressure','SkinThickness',\n",
    "            'Insulin','BMI','DiabetesPedigreeFunction','Age']\n",
    "\n",
    "fig, axs = plt.subplots(2,4, figsize=(10,5))\n",
    "axs = axs.flatten()\n",
    "\n",
    "fig.suptitle('Feature distributions')\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    axs[i].hist(training_df[feature], color='black', bins=30)\n",
    "    axs[i].set_xlabel(feature)\n",
    "    axs[i].set_ylabel('Patients')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pregnancies','Glucose','BloodPressure','SkinThickness',\n",
    "            'Insulin','BMI','DiabetesPedigreeFunction','Age']\n",
    "label = ['Outcome']\n",
    "\n",
    "training_df = training_df[features + label]\n",
    "training_df = testing_df[features + label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores = {\n",
    "    'Model': [],\n",
    "    'Score': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for constant '0' model\n",
    "accuracy = ((len(training_df) - sum(training_df['Outcome'])) / len(training_df))*100\n",
    "print(f'Training accuracy of constant \"0\" model: {accuracy:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=5000, class_weight='balanced')\n",
    "model.fit(training_df.drop('Outcome', axis=1), training_df['Outcome'])\n",
    "accuracy = accuracy_score(model.predict(training_df.drop('Outcome', axis=1)), training_df['Outcome'])*100\n",
    "print(f'Training accuracy of logistic regression model: {accuracy:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores = {\n",
    "    'Model': [],\n",
    "    'Score': []\n",
    "}\n",
    "\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    training_df.drop('Outcome', axis=1),\n",
    "    training_df['Outcome'],\n",
    "    cv=7,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cross_val_scores['Model'].extend(['Logistic regression']*len(scores))\n",
    "cross_val_scores['Score'].extend(scores*100)\n",
    "\n",
    "print(f'Logistic regression cross-validation accuracy: {np.mean(scores)*100:.1f} +/- {np.std(scores)*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(class_weight='balanced')\n",
    "model.fit(training_df.drop('Outcome', axis=1), training_df['Outcome'])\n",
    "accuracy = accuracy_score(model.predict(training_df.drop('Outcome', axis=1)), training_df['Outcome'])*100\n",
    "print(f'Training accuracy of decision tree model: {accuracy:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    model,\n",
    "    training_df.drop('Outcome', axis=1),\n",
    "    training_df['Outcome'],\n",
    "    cv=7,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cross_val_scores['Model'].extend(['Decision tree']*len(scores))\n",
    "cross_val_scores['Score'].extend(scores*100)\n",
    "\n",
    "print(f'Decision tree cross-validation accuracy: {np.mean(scores)*100:.1f} +/- {np.std(scores)*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter optimization\n",
    "\n",
    "### 4.1. Hyperparameter random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'criterion':['gini','entropy','log_loss'],\n",
    "    'splitter':['best','random'],\n",
    "    'max_depth':randint(1, 20),\n",
    "    'min_weight_fraction_leaf':loguniform(10**-5, 0.5),\n",
    "    'max_features':uniform(loc=0.1, scale=0.9),\n",
    "    'min_impurity_decrease':loguniform(10**-5, 1.0),\n",
    "    'ccp_alpha':loguniform(10**-5, 1.0)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    hyperparameters,\n",
    "    return_train_score=True,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    n_iter=10000\n",
    ")\n",
    "\n",
    "search_results = search.fit(training_df.drop('Outcome', axis=1), training_df['Outcome'])\n",
    "model = search_results.best_estimator_\n",
    "hyperparameters = search_results.best_params_\n",
    "\n",
    "print('Best hyperparameters:\\n')\n",
    "\n",
    "for key, value in hyperparameters.items():\n",
    "    print(f' {key}: {value}')\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Hyperparameter optimization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs.plot_cross_validation(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Cross-validation of optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    model,\n",
    "    training_df.drop('Outcome', axis=1),\n",
    "    training_df['Outcome'],\n",
    "    cv=7,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cross_val_scores['Model'].extend(['Optimized decision tree']*len(scores))\n",
    "cross_val_scores['Score'].extend(scores*100)\n",
    "\n",
    "print(f'Optimized decision tree cross-validation accuracy: {np.mean(scores)*100:.1f} +/- {np.std(scores)*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "### 5.1. Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(pd.DataFrame.from_dict(cross_val_scores), x='Model', y='Score')\n",
    "plt.title('Model cross-validation performance comparison')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_predictions = model.predict(testing_df.drop('Outcome', axis=1))\n",
    "accuracy = accuracy_score(testing_predictions, testing_df['Outcome'])*100\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(testing_df['Outcome'], testing_predictions, normalize='true')\n",
    "cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "_ = cm_disp.plot()\n",
    "\n",
    "plt.title(f'Optimized model test set performance\\noverall accuracy: {accuracy:.1f}%')\n",
    "plt.xlabel('Predicted outcome')\n",
    "plt.ylabel('True outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save\n",
    "\n",
    "### 6.1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw data\n",
    "Path('../data/raw').mkdir(exist_ok=True, parents=True)\n",
    "data_df.to_parquet(config.RAW_DATA_FILE)\n",
    "\n",
    "# Save processed data\n",
    "Path('../data/processed').mkdir(exist_ok=True, parents=True)\n",
    "data = {\n",
    "    'training': training_df,\n",
    "    'testing': testing_df\n",
    "}\n",
    "\n",
    "with open(config.DATA_FILE, 'wb') as output_file:\n",
    "    pickle.dump(data, output_file)\n",
    "\n",
    "# Save cross-validation scores\n",
    "with open(config.CROSS_VAL_SCORES_FILE, 'wb') as output_file:\n",
    "    pickle.dump(cross_val_scores, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('../models').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "with open(config.DECISION_TREE_HYPERPARAMETERS, 'wb') as output_file:\n",
    "    pickle.dump(hyperparameters, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.DECISION_TREE_MODEL, 'wb') as output_file:\n",
    "    pickle.dump(model, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
